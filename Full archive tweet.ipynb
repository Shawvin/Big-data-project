{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bearer_token = open(\"academic_account_token\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token='AAAAAAAAAAAAAAAAAAAAAIj%2FMQEAAAAA6cPH1MaLdqvt419c76uimt778kw%3DU6sKaOitIkA527J0i9mE7Y3AZSITtcnUzdtR2RXDvyJT1NQMHD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_url = \"https://api.twitter.com/2/tweets/search/all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional params: start_time,end_time,since_id,until_id,max_results,next_token,\n",
    "# expansions,tweet.fields,media.fields,poll.fields,place.fields,user.fields\n",
    "query_params = {'query': 'place_country:SG lang:en -is:retweet',\n",
    "                #'profile_country: Singapore',\n",
    "                'start_time':'2021-04-01T00:00:00Z',\n",
    "                'end_time':'2021-05-01T00:00:00Z',\n",
    "                #profile_point_radius:[103.800000 1.366667 25mi] \n",
    "                'tweet.fields': 'created_at,public_metrics,geo',\n",
    "                'expansions':'author_id,geo.place_id',\n",
    "                #'expansions':'geo.place_id',\n",
    "                'user.fields':'location',\n",
    "                'place.fields':'country,country_code',\n",
    "                'max_results':500 \n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, headers, params):\n",
    "    response = requests.request(\"GET\", search_url, headers=headers, params=params)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below put all the response in one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    with open('data\\tweets1.json', 'a') as outfile:\n",
    "        headers = create_headers(bearer_token)\n",
    "        json_response = connect_to_endpoint(search_url, headers, query_params)\n",
    "        tweet_count=json_response['meta']['result_count']\n",
    "        print(\"The number of tweets retrieve is: \", tweet_count)\n",
    "        next_token=json_response['meta'].get('next_token',None)\n",
    "        print(\"The next_token is: \", next_token)\n",
    "        json.dump(json_response, outfile)\n",
    "        #tweets.append(json_response)\n",
    "        \n",
    "        while(next_token!=None):\n",
    "            query_params_new = {'query': 'place_country:SG lang:en -is:retweet',\n",
    "                #'profile_country: Singapore',\n",
    "                'start_time':'2021-04-01T00:00:00Z',\n",
    "                'end_time':'2021-05-01T00:00:00Z',\n",
    "                'next_token':next_token,\n",
    "                #profile_point_radius:[103.800000 1.366667 25mi] \n",
    "                'tweet.fields': 'created_at,public_metrics,geo',\n",
    "                'expansions':'author_id,geo.place_id',\n",
    "                #'expansions':'geo.place_id',\n",
    "                'user.fields':'location',\n",
    "                'place.fields':'country,country_code',\n",
    "                'max_results':500 \n",
    "               }\n",
    "            json_response = connect_to_endpoint(search_url, headers, query_params_new)\n",
    "            tweet_count+=json_response['meta']['result_count']\n",
    "            print(\"The accumulative number of tweets retrieve is: \", tweet_count)\n",
    "            json.dump(json_response, outfile)\n",
    "            time.sleep(1)\n",
    "            #outfile.write(\";\")\n",
    "            #tweets.append(json_response)\n",
    "        #json.dump(tweets, outfile)\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below put one response in one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "The number of tweets retrieve is:  491\n",
      "The next_token is:  b26v89c19zqg8o3fostu5ghztndert481bttgki9mokfx\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosttqs0k73ndiptf442vcz0t7ixdp\n",
      "The accumulative number of tweets retrieve is:  989\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosttqpuxohzmoz05wozh5vra2csjh\n",
      "The accumulative number of tweets retrieve is:  1489\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosttqnpltpp4cp5fm0q93rmb0e3r1\n",
      "The accumulative number of tweets retrieve is:  1988\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosttqlkvlchrh3xxb6fuotc6h5665\n",
      "The accumulative number of tweets retrieve is:  2486\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosttqhcx5tp1wta3bnqmqjdn0cinx\n",
      "The accumulative number of tweets retrieve is:  2985\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosttqf706wksls7b9iescuq4ttw1p\n",
      "The accumulative number of tweets retrieve is:  3484\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosttqd1ogqpuh7tj2lcsr5bx94uwt\n",
      "The accumulative number of tweets retrieve is:  3984\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosttq8t4huih0zc5sbgrsa1imfu65\n",
      "The accumulative number of tweets retrieve is:  4483\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosttbmelzfpuh4dttonz4vt02vfr1\n",
      "The accumulative number of tweets retrieve is:  4981\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosttbk8zuhg5qckhg9pvelillbhbx\n",
      "The accumulative number of tweets retrieve is:  5477\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosttbg0fpholyl3lpbc07rrd4xmrh\n",
      "The accumulative number of tweets retrieve is:  5970\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosttbdvpfln6s8w6aj0tit3y8met9\n",
      "The accumulative number of tweets retrieve is:  6461\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosttbbq331tt3ee8acoes6mm75ev1\n",
      "The accumulative number of tweets retrieve is:  6958\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosttb9jv14h004w3qg37zhigx15dp\n",
      "The accumulative number of tweets retrieve is:  7458\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosttb7fqdm8dea89tfi7c5cjfc325\n",
      "The accumulative number of tweets retrieve is:  7956\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosttb5blokihk6rzwc0jee3mwwpdp\n",
      "The accumulative number of tweets retrieve is:  8446\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostswgs2nke5igb5dfc05hyi4cbjx\n",
      "The accumulative number of tweets retrieve is:  8944\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostswennan5rpd4czdggv9fc5lbb1\n",
      "The accumulative number of tweets retrieve is:  9442\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostswcibm0cryv9kd3b4o5nz4lw1p\n",
      "The accumulative number of tweets retrieve is:  9942\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostswabsw79se9cyqua90dvjt7vct\n",
      "The accumulative number of tweets retrieve is:  10440\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostsw87o43o3fv172nr7kmbsey35p\n",
      "The accumulative number of tweets retrieve is:  10938\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostsw62y3c04pc1o8kyi4o51nksjh\n",
      "The accumulative number of tweets retrieve is:  11436\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostsw1ue5xs6molgmf8zb4qmawl8d\n",
      "The accumulative number of tweets retrieve is:  11932\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostsvzqkfekjnxlb4cwkiaf4zbhj1\n",
      "The accumulative number of tweets retrieve is:  12429\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostsvzo5we0wanpr2yidgu77btc3h\n",
      "The accumulative number of tweets retrieve is:  12927\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostshb5tv2mitn4mgu51131pfb6gt\n",
      "The accumulative number of tweets retrieve is:  13424\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostsh90idyd7da331axa4g187j3wd\n",
      "The accumulative number of tweets retrieve is:  13923\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostsh6vrxzu2or4hgb8zd0jccxe2l\n",
      "The accumulative number of tweets retrieve is:  14421\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostsh4puz4muwh71tvmbrwo3bp3el\n",
      "The accumulative number of tweets retrieve is:  14919\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostsh0j3pa9s1r950wnc4dcst8ghp\n",
      "The accumulative number of tweets retrieve is:  15418\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostsh0gejwezbkbcjnz487t2rhe9p\n",
      "The accumulative number of tweets retrieve is:  15916\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostsgw9nemceuqm7l30adj40cm0sd\n",
      "The accumulative number of tweets retrieve is:  16414\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostsgu3f21zoa5ih0gksmmgzwfofx\n",
      "The accumulative number of tweets retrieve is:  16911\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostsgrzam4fkbzybpy56fezwlf6gt\n",
      "The accumulative number of tweets retrieve is:  17408\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosts25jw72vb4b4q4bhson8188tq5\n",
      "The accumulative number of tweets retrieve is:  17907\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosts23dnszvw0ld6oc0vrri5kyh6l\n",
      "The accumulative number of tweets retrieve is:  18400\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosts219u2h3oag4jpws8mwafeihz1\n",
      "The accumulative number of tweets retrieve is:  18897\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosts1z54688g5w8mbn87gxc5ww58d\n",
      "The accumulative number of tweets retrieve is:  19392\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosts1uwv2sn6lpc2be5erje4bxvnh\n",
      "The accumulative number of tweets retrieve is:  19888\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosts1uuggr2ua9898r9at1rx1rd6l\n",
      "The accumulative number of tweets retrieve is:  20385\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosts1sqc0v86jxt9tdh08t4rnqmbh\n",
      "The accumulative number of tweets retrieve is:  20882\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosts1qmi16zsx90sjd3u27kchunwd\n",
      "The accumulative number of tweets retrieve is:  21382\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosts1me8zaghqz4tg2qp7htdp9xtp\n",
      "The accumulative number of tweets retrieve is:  21881\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosts1mc5da8gkut7h2bedbjusu54t\n",
      "The accumulative number of tweets retrieve is:  22379\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostrmzxcm530qyefmof3dhktxhe2l\n",
      "The accumulative number of tweets retrieve is:  22876\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostrmxsx05m318pkoe5y0dsejmvst\n",
      "The accumulative number of tweets retrieve is:  23375\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostrmvmp19adzi11eewf23z1rne65\n",
      "The accumulative number of tweets retrieve is:  23869\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostrmtikpvtfoooy5itgut6ucf7gd\n",
      "The accumulative number of tweets retrieve is:  24366\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostrmrf1e3b48jzbssjqzhsrp8nzx\n",
      "The accumulative number of tweets retrieve is:  24861\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostrmp9f01xyz8e2ustm8vbdx2dfh\n",
      "The accumulative number of tweets retrieve is:  25357\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostrmn433rgmepszomc2mitm56k59\n",
      "The accumulative number of tweets retrieve is:  25852\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostrml09erxkat8sv2zvkuekev7nh\n",
      "The accumulative number of tweets retrieve is:  26349\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostrmiv8fi6sywujsi1itfuhugl8d\n",
      "The accumulative number of tweets retrieve is:  26848\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostr7uc06x0mrbmxw84nwb3quyqnx\n",
      "The accumulative number of tweets retrieve is:  27337\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostr7s7kx1w1d07s9eyql84mdrnnh\n",
      "The accumulative number of tweets retrieve is:  27834\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostr7q2jq78xgh4pgyecyj2biw96l\n",
      "The accumulative number of tweets retrieve is:  28332\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostr7lu04x597082xlwu87i6fpcot\n",
      "The accumulative number of tweets retrieve is:  28827\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostr7jp9y37cqdcjuzwtrut6w4399\n",
      "The accumulative number of tweets retrieve is:  29320\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostr7jmkpp6frevrpen8spb7sxxml\n",
      "The accumulative number of tweets retrieve is:  29818\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostr7femkr8q1red4dl1i9h0e9zel\n",
      "The accumulative number of tweets retrieve is:  30314\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostr7dassq1pt2j3dm3o9np7txxtp\n",
      "The accumulative number of tweets retrieve is:  30808\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostr7d8oxlft4pdjc3jm8gpp4wgot\n",
      "The accumulative number of tweets retrieve is:  31307\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostqsop5v2p6jjbpg3spismxjnj3x\n",
      "The accumulative number of tweets retrieve is:  31805\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostqsml161enrd3lpdbs8v88fpth9\n",
      "The accumulative number of tweets retrieve is:  32303\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostqskgm3qbkjcp5qc37uoc2xybul\n",
      "The accumulative number of tweets retrieve is:  32801\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostqsics8ois7ets97tonfkk3u6pp\n",
      "The accumulative number of tweets retrieve is:  33298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostqsg6k6po1zxckbyb0niry8o60t\n",
      "The accumulative number of tweets retrieve is:  33791\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostqse2fd5kpcihj32cha1jhqx20t\n",
      "The accumulative number of tweets retrieve is:  34288\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostqsbyayquv7bz0fnyewijfdja0t\n",
      "The accumulative number of tweets retrieve is:  34784\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostqs9sdnojicyofg8cl9u40vs1a5\n",
      "The accumulative number of tweets retrieve is:  35281\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostqs7ncjvkgwgjl6tctnp349de2l\n",
      "The accumulative number of tweets retrieve is:  35776\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostqs5imeje3qe6xzm5xj10b44ry5\n",
      "The accumulative number of tweets retrieve is:  36269\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosqut75gbglb11fr0cun7xunxubgd\n",
      "The accumulative number of tweets retrieve is:  36764\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosqut2xhl9q40gna7z5x3xg5bf725\n",
      "The accumulative number of tweets retrieve is:  37254\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosqut0t2fyol39719g3zw4hx8qnb1\n",
      "The accumulative number of tweets retrieve is:  37751\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosqusyoc61ko1r8vgwq3vapv249z1\n",
      "The accumulative number of tweets retrieve is:  38247\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosquswhtd78z43vi42gzm3g4mibul\n",
      "The accumulative number of tweets retrieve is:  38738\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosqusud39dhjtynaydvzsvj1wpzzx\n",
      "The accumulative number of tweets retrieve is:  39236\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosquss82g7idn0z726c3b5b5vubgd\n",
      "The accumulative number of tweets retrieve is:  39734\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosqusnztcrx54csmu0cmntbncfeyl\n",
      "The accumulative number of tweets retrieve is:  40226\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosque1kp9il7j81f7lprrntv44m7x\n",
      "The accumulative number of tweets retrieve is:  40721\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosqudzfdkt7st191a2uy4ei9jw3gd\n",
      "The accumulative number of tweets retrieve is:  41213\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosqudx9g58j1aywstd28t5n57z059\n",
      "The accumulative number of tweets retrieve is:  41698\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosqudv5bscfhq4ntgapcz95r7b62l\n",
      "The accumulative number of tweets retrieve is:  42197\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosqudt177ukwjurd6y1yf6wq2f4vx\n",
      "The accumulative number of tweets retrieve is:  42691\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosqudosxwtvq6jy65iu0fkmlpgdj1\n",
      "The accumulative number of tweets retrieve is:  43185\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosqudoqjjw9cwzjuwvsjzcsfruph9\n",
      "The accumulative number of tweets retrieve is:  43684\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosqudmmf8izzx8cihga55olk004n1\n",
      "The accumulative number of tweets retrieve is:  44183\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosqudkial047fv1iswreqfizdf33x\n",
      "The accumulative number of tweets retrieve is:  44679\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosqtyvyrgze02irc7kcxvsk1axqil\n",
      "The accumulative number of tweets retrieve is:  45172\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosqtyvwnrwmscz7hbo6b5aboq37nh\n",
      "The accumulative number of tweets retrieve is:  45667\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosqtytsjdijzuns8hljo6hsygsmf1\n",
      "The accumulative number of tweets retrieve is:  46163\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosqtypjz8juwvryz72qd2v44y4ltp\n",
      "The accumulative number of tweets retrieve is:  46659\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosqtynfjynvi5k75tkgiw8ecizkot\n",
      "The accumulative number of tweets retrieve is:  47156\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosqtylau3zk15xfyqh93nf57vl9x9\n",
      "The accumulative number of tweets retrieve is:  47653\n",
      "200\n",
      "The next_token is:  None\n",
      "The accumulative number of tweets retrieve is:  47978\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    with open('Apr_tweets1.json', 'a') as outfile:\n",
    "        headers = create_headers(bearer_token)\n",
    "        json_response = connect_to_endpoint(search_url, headers, query_params)\n",
    "        tweet_count=json_response['meta']['result_count']\n",
    "        print(\"The number of tweets retrieve is: \", tweet_count)\n",
    "        next_token=json_response['meta'].get('next_token',None)\n",
    "        print(\"The next_token is: \", next_token)\n",
    "        json.dump(json_response, outfile)\n",
    "        #tweets.append(json_response)\n",
    "        num=1\n",
    "        \n",
    "        while(next_token!=None):\n",
    "            num+=1\n",
    "            filename='Apr_tweets'+str(num)+'.json'\n",
    "            with open(filename, 'a') as outfile:\n",
    "                query_params_new = {'query': 'place_country:SG lang:en -is:retweet',\n",
    "                #'profile_country: Singapore',\n",
    "                'start_time':'2021-04-01T00:00:00Z',\n",
    "                'end_time':'2021-05-01T00:00:00Z',\n",
    "                'next_token':next_token,\n",
    "                #profile_point_radius:[103.800000 1.366667 25mi] \n",
    "                'tweet.fields': 'created_at,public_metrics,geo',\n",
    "                'expansions':'author_id,geo.place_id',\n",
    "                #'expansions':'geo.place_id',\n",
    "                'user.fields':'location',\n",
    "                'place.fields':'country,country_code',\n",
    "                'max_results':500 \n",
    "                   }\n",
    "                json_response = connect_to_endpoint(search_url, headers, query_params_new)\n",
    "                next_token=json_response['meta'].get('next_token',None)\n",
    "                print(\"The next_token is: \", next_token)\n",
    "                tweet_count+=json_response['meta']['result_count']\n",
    "                print(\"The accumulative number of tweets retrieve is: \", tweet_count)\n",
    "                json.dump(json_response, outfile)\n",
    "                time.sleep(1)\n",
    "            #outfile.write(\";\")\n",
    "            #tweets.append(json_response)\n",
    "        #json.dump(tweets, outfile)\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

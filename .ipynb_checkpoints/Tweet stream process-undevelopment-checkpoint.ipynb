{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, requests, sys\n",
    "from nltk.corpus import stopwords\n",
    "from operator import add\n",
    "from pyspark import SparkContext\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.streaming import StreamingContext\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text classification\n",
    "def getSentiment(text):\n",
    "    sent = TextBlob(text).sentiment.polarity\n",
    "    neutral_threshold = 0.05\n",
    "    \n",
    "    if sent >= neutral_threshold:\n",
    "        return (1, 0, 0) # positive\n",
    "    elif sent > neutral_threshold:\n",
    "        return (0, 1, 0) # neutral\n",
    "    else:\n",
    "        return (0, 0, 1) # negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTweetsCounter(dstream_tweets_sentiment_analysed, window_length, sliding_interval):\n",
    "\n",
    "    tweets_to_count = dstream_tweets_sentiment_analysed. \\\n",
    "        map(lambda x: ('count', (1, x[2])))\n",
    "\n",
    "    tweets_count_acc_sent = tweets_to_count. \\\n",
    "        reduceByKeyAndWindow(lambda x, y: (x[0] + y[0], (x[1][0] + y[1][0], x[1][1] + y[1][1], x[1][2] + y[1][2])), None,\n",
    "                             window_length, sliding_interval)\n",
    "\n",
    "    total_count = tweets_count_acc_sent. \\\n",
    "        map(lambda x: x[1])\n",
    "    \n",
    "    total_count.pprint()\n",
    "    return total_count\n",
    "    \n",
    "def sendTweetsCounter(sentiments, url):\n",
    "    def takeAndSend(time, rdd):\n",
    "        if not rdd.isEmpty():\n",
    "            (name, (total, (pos, neutral, neg))) = rdd.first()\n",
    "\n",
    "            json_data = {'positive': pos, 'neutral': neutral, 'negative': neg, 'total': total}\n",
    "            #print(json_data)\n",
    "\n",
    "            response = requests.post(url, data=json_data)\n",
    "\n",
    "    sentiments.foreachRDD(takeAndSend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTweets(kvs):\n",
    "    tweets_text = kvs.map(lambda x: json.loads(x)) \\\n",
    "                .map(lambda json_object: (json_object[\"user\"][\"screen_name\"], json_object[\"text\"], json_object[\"user\"][\"followers_count\"], json_object[\"id\"])) \\\n",
    "                .transform(lambda rdd: rdd.sortBy(lambda x: x[2], ascending = False))\n",
    "    \n",
    "    tweets_text.pprint()\n",
    "    return tweets_text\n",
    "    \n",
    "def sendTweets(tweets, url):\n",
    "    def takeAndSend(time, rdd):\n",
    "        if not rdd.isEmpty():\n",
    "            tweets_data = rdd.take(10)\n",
    "\n",
    "            users = []\n",
    "            texts = []\n",
    "            tweet_ids = []\n",
    "\n",
    "            for (user, text, follower_count, tweet_id) in tweets_data:\n",
    "                users.append(user)\n",
    "                texts.append(text)\n",
    "                tweet_ids.append(tweet_id)\n",
    "\n",
    "            json_data = {'user': str(users), 'text': str(texts), 'id': str(tweet_ids)}\n",
    "            print(json_data)\n",
    "\n",
    "            response = requests.post(url, data=json_data)\n",
    "\n",
    "    tweets.foreachRDD(takeAndSend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopWords(tweets, window_length, sliding_interval):\n",
    "    lines = tweets.flatMap(lambda line: line[1].split(\" \"))\n",
    "\n",
    "    ## This part does the word count\n",
    "    sw = stopwords.words('english')\n",
    "    sw.extend(['rt', 'https', 'http', 'coronavirus', 'covid19', 'covid-19'])\n",
    "    \n",
    "    counts = lines.map(lambda word: word.strip().lower()) \\\n",
    "                  .filter(lambda word: word not in sw) \\\n",
    "                  .filter(lambda word: len(word) >= 2 and word[0] != '#' and word[0] != '@') \\\n",
    "                  .map(lambda word: (word, 1)) \\\n",
    "                  .reduceByKeyAndWindow(add, None,  window_length, sliding_interval)\\\n",
    "                  .transform(lambda rdd: rdd.sortBy(lambda x: x[1], ascending = False))\n",
    "    \n",
    "    counts.pprint()\n",
    "    return counts\n",
    "    \n",
    "def sendTopWords(counts, url):\n",
    "    def takeAndSend(time, rdd):\n",
    "        if not rdd.isEmpty():\n",
    "            word_counts = rdd.take(10)\n",
    "\n",
    "            words = []\n",
    "            values = []\n",
    "\n",
    "            for (word, count) in word_counts:\n",
    "                words.append(word)\n",
    "                values.append(count)\n",
    "\n",
    "            json_data = {'words': str(words), 'counts': str(values)}\n",
    "            print(json_data)\n",
    "\n",
    "            response = requests.post(url, data=json_data)\n",
    "\n",
    "    counts.foreachRDD(takeAndSend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopHashTags(dstream_tweets_sentiment_analysed, window_length, sliding_interval):\n",
    "    hashtags = dstream_tweets_sentiment_analysed.\\\n",
    "            map(lambda x: ((x[0], x[2]), x[1])).\\\n",
    "            flatMapValues(lambda text: text.split(\" \")).\\\n",
    "            filter(lambda x: len(x[1]) > 1 and x[1][0] == '#'). \\\n",
    "            map(lambda x: (x[1], (1, x[0][1])))\n",
    "    \n",
    "    hashtags_count_acc_sent = hashtags. \\\n",
    "        reduceByKeyAndWindow(lambda x, y: (x[0] + y[0], (x[1][0] + y[1][0], x[1][1] + y[1][1], x[1][2] + y[1][2])), None,\n",
    "                             window_length, sliding_interval)\n",
    "    \n",
    "    sorted_hashtags_count = hashtags_count_acc_sent. \\\n",
    "        map(lambda x: (x[1][0], (x[0], x[1][1]))). \\\n",
    "        transform(lambda rdd: rdd.sortByKey(False)). \\\n",
    "        map(lambda x: (x[1][0], (x[0], x[1][1])))\n",
    "\n",
    "    \n",
    "    sorted_hashtags_count.pprint()\n",
    "    return sorted_hashtags_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopMentioned(dstream_tweets_sentiment_analysed, window_length, sliding_interval):\n",
    "    mentioned = dstream_tweets_sentiment_analysed.\\\n",
    "            map(lambda x: ((x[0], x[2]), x[1])).\\\n",
    "            flatMapValues(lambda text: text.split(\" \")).\\\n",
    "            filter(lambda x: len(x[1]) > 1 and x[1][0] == '@'). \\\n",
    "            map(lambda x: (x[1], (1, x[0][1])))\n",
    "    \n",
    "    mentioned_count_acc_sent = mentioned. \\\n",
    "        reduceByKeyAndWindow(lambda x, y: (x[0] + y[0], (x[1][0] + y[1][0], x[1][1] + y[1][1], x[1][2] + y[1][2])), None,\n",
    "                             window_length, sliding_interval)\n",
    "    \n",
    "    sorted_mentioned_count = mentioned_count_acc_sent. \\\n",
    "        map(lambda x: (x[1][0], (x[0], x[1][1]))). \\\n",
    "        transform(lambda rdd: rdd.sortByKey(False)). \\\n",
    "        map(lambda x: (x[1][0], (x[0], x[1][1])))\n",
    "\n",
    "\n",
    "    sorted_mentioned_count.pprint()\n",
    "    return sorted_mentioned_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopActive(dstream_tweets_sentiment_analysed, window_length, sliding_interval):\n",
    "    active=dstream_tweets_sentiment_analysed. \\\n",
    "        map(lambda x: (x[0], (1, x[2])))\n",
    "    \n",
    "    user_count_acc_sent = active. \\\n",
    "        reduceByKeyAndWindow(lambda x, y: (x[0] + y[0], (x[1][0] + y[1][0], x[1][1] + y[1][1], x[1][2] + y[1][2])), None,\n",
    "                             window_length, sliding_interval)\n",
    "    \n",
    "    sorted_users_count = user_count_acc_sent. \\\n",
    "        map(lambda x: (x[1][0], (x[0], x[1][1]))). \\\n",
    "        transform(lambda rdd: rdd.sortByKey(False)). \\\n",
    "        map(lambda x: (x[1][0], (x[0], x[1][1])))\n",
    "    \n",
    "    sorted_users_count.pprint()\n",
    "    return sorted_users_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_top_to_dashboard(dstream_tweets_sentiment_analysed, url):\n",
    "\n",
    "    num = 10\n",
    "\n",
    "    def take_and_send(time, rdd):\n",
    "        if not rdd.isEmpty():\n",
    "            taken = rdd.take(num)\n",
    "\n",
    "            labels = []\n",
    "            negative = []\n",
    "            neutral = []\n",
    "            positive = []\n",
    "            for (name, (count, (pos, neu, neg))) in taken:\n",
    "                labels.append(name)\n",
    "                negative.append(neg)\n",
    "                neutral.append(neu)\n",
    "                positive.append(pos)\n",
    "\n",
    "            request_data = {'label': str(labels), 'negative': str(negative), 'neutral': str(neutral), 'positive': str(positive)}\n",
    "            response = requests.post(url, data=request_data)\n",
    "\n",
    "    dstream_tweets_sentiment_analysed.foreachRDD(take_and_send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(appName=\"tweetStream\")\n",
    "# Create a local StreamingContext with batch interval of 2 second\n",
    "batch_interval = 2\n",
    "window_length = 15*60\n",
    "sliding_interval = 6\n",
    "\n",
    "ssc = StreamingContext(sc, batch_interval)\n",
    "ssc.checkpoint(\"twittercheckpt\")\n",
    "\n",
    "# Create a DStream that conencts to hostname:port\n",
    "tweetStream = ssc.socketTextStream(\"0.0.0.0\", 5555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweetStream. \\\n",
    "        map(lambda  x: json.loads(x)). \\\n",
    "        map(lambda json_object: (json_object[\"user\"][\"screen_name\"], json_object[\"text\"]))\n",
    "\n",
    "tweets_sentiment_analysed = tweets. \\\n",
    "        map(lambda x: (x[0], x[1], getSentiment(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.streaming.dstream.TransformedDStream at 0x7fbe010d6c40>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_sentiment_analysed.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'http://localhost:5000/'\n",
    "\n",
    "tweet_counters = getTweetsCounter(tweets_sentiment_analysed, window_length, sliding_interval)\n",
    "sendTweetsCounter(tweet_counters,  server +'update_sentiments')\n",
    "\n",
    "tweet_text= getTweets(tweetStream)\n",
    "sendTweets(tweet_text, server + 'update_tweets')\n",
    "\n",
    "key_words=getTopWords(tweets, window_length, sliding_interval)\n",
    "sendTopWords(key_words, server + 'update_counts')\n",
    "\n",
    "hashtag=getTopHashTags(tweets_sentiment_analysed, window_length, sliding_interval)\n",
    "mention=getTopMentioned(tweets_sentiment_analysed, window_length, sliding_interval)\n",
    "activeuser=getTopActive(tweets_sentiment_analysed, window_length, sliding_interval)\n",
    "\n",
    "send_top_to_dashboard(hashtag)\n",
    "send_top_to_dashboard(mention)\n",
    "send_top_to_dashboard(activeuser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.streaming.dstream.TransformedDStream at 0x7fbe010d80a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getTopActive(tweets_sentiment_analysed, window_length, sliding_interval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.streaming.dstream.TransformedDStream at 0x7f8bb7ed5d30>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getTopMentioned(tweets_sentiment_analysed, window_length, sliding_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2021-05-26 16:37:24\n",
      "-------------------------------------------\n",
      "('Shambles151', (1, (0, 0, 1)))\n",
      "('LincsLimpet', (1, (0, 0, 1)))\n",
      "('bryspeed1e', (1, (0, 0, 1)))\n",
      "('RiteshY15653204', (1, (1, 0, 0)))\n",
      "('Sakthim08061171', (1, (0, 0, 1)))\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-05-26 16:37:30\n",
      "-------------------------------------------\n",
      "('Shambles151', (1, (0, 0, 1)))\n",
      "('Sangfro76889793', (1, (1, 0, 0)))\n",
      "('ASTRALlife_', (1, (0, 0, 1)))\n",
      "('Hairyloon', (1, (1, 0, 0)))\n",
      "('LincsLimpet', (1, (0, 0, 1)))\n",
      "('AmberL_77', (1, (0, 0, 1)))\n",
      "('marciaj64', (1, (0, 0, 1)))\n",
      "('MonicaChangFury', (1, (1, 0, 0)))\n",
      "('pdr212004', (1, (0, 0, 1)))\n",
      "('slganesh1', (1, (0, 0, 1)))\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-05-26 16:37:36\n",
      "-------------------------------------------\n",
      "('RiteshY15653204', (3, (2, 0, 1)))\n",
      "('LincsLimpet', (2, (1, 0, 1)))\n",
      "('IamPunithGowda', (1, (0, 0, 1)))\n",
      "('Shambles151', (1, (0, 0, 1)))\n",
      "('Sangfro76889793', (1, (1, 0, 0)))\n",
      "('ASTRALlife_', (1, (0, 0, 1)))\n",
      "('Hairyloon', (1, (1, 0, 0)))\n",
      "('AmberL_77', (1, (0, 0, 1)))\n",
      "('marciaj64', (1, (0, 0, 1)))\n",
      "('MonicaChangFury', (1, (1, 0, 0)))\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-05-26 16:37:42\n",
      "-------------------------------------------\n",
      "('RiteshY15653204', (3, (2, 0, 1)))\n",
      "('LincsLimpet', (2, (1, 0, 1)))\n",
      "('AmberL_77', (2, (0, 0, 2)))\n",
      "('deepvard', (2, (0, 0, 2)))\n",
      "('IamPunithGowda', (1, (0, 0, 1)))\n",
      "('Shambles151', (1, (0, 0, 1)))\n",
      "('Sangfro76889793', (1, (1, 0, 0)))\n",
      "('ASTRALlife_', (1, (0, 0, 1)))\n",
      "('Hairyloon', (1, (1, 0, 0)))\n",
      "('BigMommaLurka', (1, (1, 0, 0)))\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-05-26 16:37:48\n",
      "-------------------------------------------\n",
      "('RiteshY15653204', (3, (2, 0, 1)))\n",
      "('LincsLimpet', (2, (1, 0, 1)))\n",
      "('AmberL_77', (2, (0, 0, 2)))\n",
      "('deepvard', (2, (0, 0, 2)))\n",
      "('IamPunithGowda', (1, (0, 0, 1)))\n",
      "('Shambles151', (1, (0, 0, 1)))\n",
      "('Sangfro76889793', (1, (1, 0, 0)))\n",
      "('ASTRALlife_', (1, (0, 0, 1)))\n",
      "('Hairyloon', (1, (1, 0, 0)))\n",
      "('BigMommaLurka', (1, (1, 0, 0)))\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-05-26 16:37:54\n",
      "-------------------------------------------\n",
      "('RiteshY15653204', (3, (2, 0, 1)))\n",
      "('LincsLimpet', (2, (1, 0, 1)))\n",
      "('AmberL_77', (2, (0, 0, 2)))\n",
      "('abhinitk', (2, (1, 0, 1)))\n",
      "('deepvard', (2, (0, 0, 2)))\n",
      "('IamPunithGowda', (1, (0, 0, 1)))\n",
      "('Shambles151', (1, (0, 0, 1)))\n",
      "('Sangfro76889793', (1, (1, 0, 0)))\n",
      "('ASTRALlife_', (1, (0, 0, 1)))\n",
      "('Hairyloon', (1, (1, 0, 0)))\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-05-26 16:38:00\n",
      "-------------------------------------------\n",
      "('RiteshY15653204', (3, (2, 0, 1)))\n",
      "('LincsLimpet', (2, (1, 0, 1)))\n",
      "('AmberL_77', (2, (0, 0, 2)))\n",
      "('abhinitk', (2, (1, 0, 1)))\n",
      "('deepvard', (2, (0, 0, 2)))\n",
      "('IamPunithGowda', (1, (0, 0, 1)))\n",
      "('vickiw32', (1, (0, 0, 1)))\n",
      "('Shambles151', (1, (0, 0, 1)))\n",
      "('Sangfro76889793', (1, (1, 0, 0)))\n",
      "('ASTRALlife_', (1, (0, 0, 1)))\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-05-26 16:38:06\n",
      "-------------------------------------------\n",
      "('RiteshY15653204', (3, (2, 0, 1)))\n",
      "('LincsLimpet', (2, (1, 0, 1)))\n",
      "('AmberL_77', (2, (0, 0, 2)))\n",
      "('abhinitk', (2, (1, 0, 1)))\n",
      "('deepvard', (2, (0, 0, 2)))\n",
      "('IamPunithGowda', (1, (0, 0, 1)))\n",
      "('vickiw32', (1, (0, 0, 1)))\n",
      "('sugnanags', (1, (1, 0, 0)))\n",
      "('MOHIT786111', (1, (1, 0, 0)))\n",
      "('Shambles151', (1, (0, 0, 1)))\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-05-26 16:38:12\n",
      "-------------------------------------------\n",
      "('RiteshY15653204', (3, (2, 0, 1)))\n",
      "('MOHIT786111', (2, (2, 0, 0)))\n",
      "('LincsLimpet', (2, (1, 0, 1)))\n",
      "('AmberL_77', (2, (0, 0, 2)))\n",
      "('abhinitk', (2, (1, 0, 1)))\n",
      "('deepvard', (2, (0, 0, 2)))\n",
      "('IamPunithGowda', (1, (0, 0, 1)))\n",
      "('vickiw32', (1, (0, 0, 1)))\n",
      "('sugnanags', (1, (1, 0, 0)))\n",
      "('JennyJones1313', (1, (0, 0, 1)))\n",
      "...\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9e3affcc1f54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Wait for termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopGraceFully\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/pyspark/streaming/context.py\u001b[0m in \u001b[0;36mawaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \"\"\"\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTerminationOrTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start computing\n",
    "ssc.start()        \n",
    "# Wait for termination\n",
    "ssc.awaitTermination()\n",
    "ssc.stop(stopGraceFully = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'http://localhost:5000/'\n",
    "geodata_path='/Users/shawvin/Desktop/Big data project/geo_tweets.txt'\n",
    "\n",
    "sendGeoData(geodata_path, server + 'update_geodata')\n",
    "sendTweetsFromStream(kvs, server + 'update_tweets')\n",
    "sendTopHashtagsFromStream(kvs, server + 'update_hashtagcounts')\n",
    "sendTopWordsFromStream(kvs, server + 'update_counts')\n",
    "sendTweetSentimentsFromStream(kvs, server + 'update_sentiments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

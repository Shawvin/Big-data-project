{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, requests, sys\n",
    "from nltk.corpus import stopwords\n",
    "from operator import add\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text classification\n",
    "def sendTopWords(counts, url):\n",
    "    def takeAndSend(time, rdd):\n",
    "        if not rdd.isEmpty():\n",
    "            word_counts = rdd.take(10)\n",
    "\n",
    "            words = []\n",
    "            values = []\n",
    "\n",
    "            for (word, count) in word_counts:\n",
    "                words.append(word)\n",
    "                values.append(count)\n",
    "\n",
    "            json_data = {'words': str(words), 'counts': str(values)}\n",
    "            print(json_data)\n",
    "\n",
    "            response = requests.post(url, data=json_data)\n",
    "\n",
    "    counts.foreachRDD(takeAndSend)\n",
    "\n",
    "\n",
    "def sendTweets(tweets, url):\n",
    "    def takeAndSend(time, rdd):\n",
    "        if not rdd.isEmpty():\n",
    "            tweets_data = rdd.take(10)\n",
    "\n",
    "            users = []\n",
    "            texts = []\n",
    "            tweet_ids = []\n",
    "\n",
    "            for (user, text, follower_count, tweet_id) in tweets_data:\n",
    "                users.append(user)\n",
    "                texts.append(text)\n",
    "                tweet_ids.append(tweet_id)\n",
    "\n",
    "            json_data = {'user': str(users), 'text': str(texts), 'id': str(tweet_ids)}\n",
    "            print(json_data)\n",
    "\n",
    "            response = requests.post(url, data=json_data)\n",
    "\n",
    "    tweets.foreachRDD(takeAndSend)\n",
    "\n",
    "\n",
    "def sendTweetSentiments(sentiments, url):\n",
    "    def takeAndSend(time, rdd):\n",
    "        if not rdd.isEmpty():\n",
    "            (name, (total, (pos, neutral, neg))) = rdd.first()\n",
    "\n",
    "            json_data = {'positive': pos, 'neutral': neutral, 'negative': neg, 'total': total}\n",
    "            print(json_data)\n",
    "\n",
    "            response = requests.post(url, data=json_data)\n",
    "\n",
    "    sentiments.foreachRDD(takeAndSend)\n",
    "\n",
    "\n",
    "def sendGeoData(path, url):\n",
    "    filepath = \"file:///\" + path\n",
    "    geodata = sc.textFile(filepath) \\\n",
    "                .map(lambda x: x.encode(\"ascii\", \"ignore\")) \\\n",
    "                .map(lambda x: json.loads(x)) \\\n",
    "                .map(lambda json_object: (json_object[\"user\"][\"screen_name\"], json_object[\"coordinates\"])) \\\n",
    "                .map(lambda kv: (kv[1]['coordinates'][0], kv[1]['coordinates'][1])) \\\n",
    "                .collect()\n",
    "\n",
    "    longitudes = []\n",
    "    latitudes = []\n",
    "\n",
    "    for geotweet in geodata:\n",
    "        longitudes.append(geotweet[0])\n",
    "        latitudes.append(geotweet[1])\n",
    "\n",
    "    json_data = {'longitude': str(longitudes), 'latitude': str(latitudes)}\n",
    "    response = requests.post(url, data=json_data)\n",
    "\n",
    "\n",
    "def sendTweetsFromStream(kvs, url):\n",
    "    tweets = kvs.map(lambda x: x[1].encode(\"ascii\", \"ignore\")) \\\n",
    "                .map(lambda x: json.loads(x)) \\\n",
    "                .map(lambda json_object: (json_object[\"user\"][\"screen_name\"], json_object[\"text\"], json_object[\"user\"][\"followers_count\"], json_object[\"id\"])) \\\n",
    "                .transform(lambda rdd: rdd.sortBy(lambda x: x[2], ascending = False))\n",
    "    tweets.pprint()\n",
    "    sendTweets(tweets, url)\n",
    "\n",
    "\n",
    "def getSentiment(text):\n",
    "    sent = TextBlob(text).sentiment.polarity\n",
    "\n",
    "    if sent > 0:\n",
    "        return (1, 0, 0)\n",
    "    elif sent == 0:\n",
    "        return (0, 1, 0)\n",
    "    else:\n",
    "        return (0, 0, 1)\n",
    "\n",
    "\n",
    "def sendTweetSentimentsFromStream(kvs, url):\n",
    "    sentiments = kvs.map(lambda x: x[1].encode(\"ascii\", \"ignore\")) \\\n",
    "                    .map(lambda x: json.loads(x)) \\\n",
    "                    .map(lambda json_object: (json_object[\"user\"][\"screen_name\"], json_object[\"text\"], getSentiment(json_object[\"text\"]))) \\\n",
    "                    .map(lambda kv: ('count', (1, kv[2]))) \\\n",
    "                    .reduceByKey(lambda a, b: (a[0] + b[0], (a[1][0] + b[1][0], a[1][1] + b[1][1], a[1][2] + b[1][2])))\n",
    "    sentiments.pprint()\n",
    "    sendTweetSentiments(sentiments, url)\n",
    "\n",
    "\n",
    "def sendTopHashtagsFromStream(kvs, url):\n",
    "    tweets = kvs.map(lambda x: x[1].encode(\"ascii\", \"ignore\")) \\\n",
    "                .map(lambda x: json.loads(x)) \\\n",
    "                .map(lambda json_object: (json_object[\"user\"][\"screen_name\"], json_object[\"text\"]))\n",
    "\n",
    "    lines = tweets.flatMap(lambda line: line[1].split(\" \"))\n",
    "\n",
    "    ## This part does the hashtag count\n",
    "    hashtag_counts = lines.filter(lambda word: len(word) >= 2 and word[0] == '#') \\\n",
    "                          .map(lambda word: (word, 1)) \\\n",
    "                          .reduceByKey(add) \\\n",
    "                          .transform(lambda rdd: rdd.sortBy(lambda x: x[1], ascending = False))\n",
    "    hashtag_counts.pprint()\n",
    "    sendTopWords(hashtag_counts, url)\n",
    "\n",
    "\n",
    "def sendTopWordsFromStream(kvs, url):\n",
    "    tweets = kvs.map(lambda x: x[1].encode(\"ascii\", \"ignore\")) \\\n",
    "                .map(lambda x: json.loads(x)) \\\n",
    "                .map(lambda json_object: (json_object[\"user\"][\"screen_name\"], json_object[\"text\"]))\n",
    "\n",
    "    lines = tweets.flatMap(lambda line: line[1].split(\" \"))\n",
    "\n",
    "    ## This part does the word count\n",
    "    sw = stopwords.words('english')\n",
    "    sw.extend(['rt', 'https', 'http', 'coronavirus', 'covid19', 'covid-19'])\n",
    "\n",
    "    counts = lines.map(lambda word: word.strip().lower()) \\\n",
    "                  .filter(lambda word: word not in sw) \\\n",
    "                  .filter(lambda word: len(word) >= 2 and word[0] != '#' and word[0] != '@') \\\n",
    "                  .map(lambda word: (word, 1)) \\\n",
    "                  .reduceByKey(add) \\\n",
    "                  .transform(lambda rdd: rdd.sortBy(lambda x: x[1], ascending = False))\n",
    "    counts.pprint()\n",
    "    sendTopWords(counts, url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(appName=\"tweetStream\")\n",
    "# Create a local StreamingContext with batch interval of 2 second\n",
    "ssc = StreamingContext(sc, 2)\n",
    "# Create a DStream that conencts to hostname:port\n",
    "kvs = ssc.socketTextStream(\"0.0.0.0\", 5555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Tweets\n",
    "words = kvs.map(lambda s: json.loads(s)['text'].lower())\n",
    "# Print the first ten elements of each DStream RDD to the console\n",
    "words.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'http://localhost:5000/'\n",
    "\n",
    "#sendGeoData(geodata_path, server + 'update_geodata')\n",
    "sendTweetsFromStream(kvs, server + 'update_tweets')\n",
    "sendTopHashtagsFromStream(kvs, server + 'update_hashtagcounts')\n",
    "sendTopWordsFromStream(kvs, server + 'update_counts')\n",
    "sendTweetSentimentsFromStream(kvs, server + 'update_sentiments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start computing\n",
    "ssc.start()        \n",
    "# Wait for termination\n",
    "ssc.awaitTerminationOrTimeout(60)\n",
    "ssc.stop(stopGraceFully = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bearer_token = open(\"academic_account_token\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token='AAAAAAAAAAAAAAAAAAAAAIj%2FMQEAAAAA6cPH1MaLdqvt419c76uimt778kw%3DU6sKaOitIkA527J0i9mE7Y3AZSITtcnUzdtR2RXDvyJT1NQMHD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_url = \"https://api.twitter.com/2/tweets/search/all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional params: start_time,end_time,since_id,until_id,max_results,next_token,\n",
    "# expansions,tweet.fields,media.fields,poll.fields,place.fields,user.fields\n",
    "query_params = {'query': 'has:geo lang:en myanmar',\n",
    "                #'profile_country: Singapore',\n",
    "                'start_time':'2021-05-01T00:00:00Z',\n",
    "                'end_time':'2021-05-28T00:00:00Z',\n",
    "                #profile_point_radius:[103.800000 1.366667 25mi] \n",
    "                'tweet.fields': 'created_at,geo',\n",
    "                #'expansions':'author_id,geo.place_id',\n",
    "                #'expansions':'geo.place_id',\n",
    "                #'user.fields':'location',\n",
    "                #'place.fields':'country,country_code',\n",
    "                'max_results':500 \n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, headers, params):\n",
    "    response = requests.request(\"GET\", search_url, headers=headers, params=params)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below put all the response in one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    with open('data/tweets_geo.json', 'a') as outfile:\n",
    "        headers = create_headers(bearer_token)\n",
    "        json_response = connect_to_endpoint(search_url, headers, query_params)\n",
    "        tweet_count=json_response['meta']['result_count']\n",
    "        print(\"The number of tweets retrieve is: \", tweet_count)\n",
    "        next_token=json_response['meta'].get('next_token',None)\n",
    "        print(\"The next_token is: \", next_token)\n",
    "        json.dump(json_response, outfile)\n",
    "        #tweets.append(json_response)\n",
    "        \n",
    "        while(next_token!=None):\n",
    "            query_params_new = {'query': 'place_country:SG lang:en -is:retweet',\n",
    "                #'profile_country: Singapore',\n",
    "                'start_time':'2021-04-01T00:00:00Z',\n",
    "                'end_time':'2021-05-01T00:00:00Z',\n",
    "                'next_token':next_token,\n",
    "                #profile_point_radius:[103.800000 1.366667 25mi] \n",
    "                'tweet.fields': 'created_at,public_metrics,geo',\n",
    "                'expansions':'author_id,geo.place_id',\n",
    "                #'expansions':'geo.place_id',\n",
    "                'user.fields':'location',\n",
    "                'place.fields':'country,country_code',\n",
    "                'max_results':500 \n",
    "               }\n",
    "            json_response = connect_to_endpoint(search_url, headers, query_params_new)\n",
    "            tweet_count+=json_response['meta']['result_count']\n",
    "            print(\"The accumulative number of tweets retrieve is: \", tweet_count)\n",
    "            json.dump(json_response, outfile)\n",
    "            time.sleep(1)\n",
    "            #outfile.write(\";\")\n",
    "            #tweets.append(json_response)\n",
    "        #json.dump(tweets, outfile)\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below put one response in one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "The number of tweets retrieve is:  500\n",
      "The next_token is:  b26v89c19zqg8o3foswt3id48e1bgkua3cajh9zsri1dp\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3foswt35m8zxfmmi9iunjlwtebj04u5\n",
      "The accumulative number of tweets retrieve is:  996\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3foswso24qnd4s4w0csqs4fibpgjla5\n",
      "The accumulative number of tweets retrieve is:  1496\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fosws90rng4367e8neb0t69r8kkgal\n",
      "The accumulative number of tweets retrieve is:  1995\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3foswru1lzjjso1lssqihuhihi920zh\n",
      "The accumulative number of tweets retrieve is:  2495\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3foswrtt1vkxz5ciuazkw2s5d9x7x4t\n",
      "The accumulative number of tweets retrieve is:  2993\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3foswrtifg3025zusp2e7s5e90m1tod\n",
      "The accumulative number of tweets retrieve is:  3491\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3foswrela0cuq912owb2glgqjk8osxp\n",
      "The accumulative number of tweets retrieve is:  3987\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3foswqzjzmh0yj419m5m2pwd05qd75p\n",
      "The accumulative number of tweets retrieve is:  4482\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3foswqkggm09anj66hntu8ocgvrsl19\n",
      "The accumulative number of tweets retrieve is:  4976\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostul361mqc52y0x1hyg2ztsb848t\n",
      "The accumulative number of tweets retrieve is:  5473\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostuko99ccn3h5bxfg3l747k53ybh\n",
      "The accumulative number of tweets retrieve is:  5971\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostu5vfobaepmglwxvle43wnrqcfx\n",
      "The accumulative number of tweets retrieve is:  6469\n",
      "200\n",
      "The next_token is:  b26v89c19zqg8o3fostu5ktuiqoka5lbt1p2qyo82m83h\n",
      "The accumulative number of tweets retrieve is:  6969\n",
      "200\n",
      "The next_token is:  None\n",
      "The accumulative number of tweets retrieve is:  7056\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    with open('geoData/tweet_geo1.json', 'a') as outfile:\n",
    "        headers = create_headers(bearer_token)\n",
    "        json_response = connect_to_endpoint(search_url, headers, query_params)\n",
    "        tweet_count=json_response['meta']['result_count']\n",
    "        print(\"The number of tweets retrieve is: \", tweet_count)\n",
    "        next_token=json_response['meta'].get('next_token',None)\n",
    "        print(\"The next_token is: \", next_token)\n",
    "        json.dump(json_response, outfile)\n",
    "        #tweets.append(json_response)\n",
    "        num=1\n",
    "        \n",
    "        while(next_token!=None):\n",
    "            num+=1\n",
    "            filename='geoData/tweet_geo'+str(num)+'.json'\n",
    "            with open(filename, 'a') as outfile:\n",
    "                query_params_new = {'next_token':next_token,\n",
    "                                    'query': 'has:geo lang:en myanmar',\n",
    "                                     'start_time':'2021-05-01T00:00:00Z',\n",
    "                                     'end_time':'2021-05-28T00:00:00Z',\n",
    "                                     'tweet.fields': 'created_at,geo',\n",
    "                                     'max_results':500 \n",
    "                                    }\n",
    "                json_response = connect_to_endpoint(search_url, headers, query_params_new)\n",
    "                next_token=json_response['meta'].get('next_token',None)\n",
    "                print(\"The next_token is: \", next_token)\n",
    "                tweet_count+=json_response['meta']['result_count']\n",
    "                print(\"The accumulative number of tweets retrieve is: \", tweet_count)\n",
    "                json.dump(json_response, outfile)\n",
    "                time.sleep(1)\n",
    "            #outfile.write(\";\")\n",
    "            #tweets.append(json_response)\n",
    "        #json.dump(tweets, outfile)\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
